{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import metapack as mp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "mp.jupyter.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>500K US Business Points</h1>\n",
       "<p><code>civicknowledge.com-scorepoints-demosearch-1.1.1</code> Last Update: 2021-06-04T21:02:45</p>\n",
       "<p><em>Point locations for 500K US businesses, primarily shopping, entertainment, food and automomobile related.</em></p>\n",
       "<p>Run the build.ipynb notebook to generate the points, if \n",
       "they don't already exist. THen build the packages with metapack.</p>\n",
       "<h2>Contacts</h2>\n",
       "<ul>\n",
       "<li><strong>Wrangler</strong> <a href=\"mailto:eric@civicknowledge.com\">Eric Busboom</a>, <a href=\"http://civicknowledge.com\">Civic Knowledge</a></li>\n",
       "</ul>\n",
       "<h2>Resources</h2>\n",
       "<ul>\n",
       "<li><strong> <a href=\"data/business_points.csv\">business_points</a></strong>. US Business points</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "# 500K US Business Points\n",
       "`civicknowledge.com-scorepoints-demosearch-1.1.1` Last Update: 2021-06-04T21:02:45\n",
       "\n",
       "_Point locations for 500K US businesses, primarily shopping, entertainment, food and automomobile related._\n",
       "\n",
       "\n",
       "Run the build.ipynb notebook to generate the points, if \n",
       "they don't already exist. THen build the packages with metapack.\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "## Contacts\n",
       "\n",
       "* **Wrangler** [Eric Busboom](mailto:eric@civicknowledge.com), [Civic Knowledge](http://civicknowledge.com)\n",
       "\n",
       "## Resources\n",
       "\n",
       "* ** [business_points](data/business_points.csv)**. US Business points\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pkg = mp.jupyter.open_package()\n",
    "pkg = mp.jupyter.open_source_package()\n",
    "pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>US Businesses</h1>\n",
       "<p><code>businesslistdatabase.com-us_business-1.1.1</code> Last Update: 2021-04-09T23:19:03</p>\n",
       "<p><em>US Business list, reduced to point position and category</em></p>\n",
       "<p>This package processes a list of US businesses obtained from a\n",
       "<a href=\"https://www.businesslistdatabase.com/\">private source</a>. The\n",
       "source data is low quality, so there is a lot of processing\n",
       "to be done. Most importantly, many records have a conflict between \n",
       "the SIC and NAICS codes; these records are removed. </p>\n",
       "<h2>Building</h2>\n",
       "<p>The package can take muh longer to build than the timeout for \n",
       "running a Jupyter notebook, so the Jupyter notebook caches\n",
       "intermediate stages of the process. Run the upyter notebook directly\n",
       "first, then build the package.</p>\n",
       "<h2>Documentation Links</h2>\n",
       "<ul>\n",
       "<li><a href=\"http://s3.amazonaws.com/radius.civicknowledge.com/businesslistdatabase.com-us_business-1.1.1/index.html\">Documentation Page</a> </li>\n",
       "</ul>\n",
       "<h2>Contacts</h2>\n",
       "<ul>\n",
       "<li><strong>Wrangler</strong> <a href=\"mailto:eric@civicknowledge.com\">Eric Busboom</a>, <a href=\"http://civicknowledge.com\">Civic Knowledge</a></li>\n",
       "</ul>\n",
       "<h2>Resources</h2>\n",
       "<ul>\n",
       "<li><strong> <a href=\"http://s3.amazonaws.com/radius.civicknowledge.com/businesslistdatabase.com-us_business-1.1.1/data/businesses_cat.csv\">businesses_cat</a></strong>. Businesses categorized to shop, auto, food, ent</li>\n",
       "</ul>\n",
       "<h2>References</h2>\n",
       "<ul><li> <strong>us_business</string>, <em>data/us_businesses.zip</em>. List of US Businesses</li><li> <strong>block_templ</string>, <em>censusgeo://2020/5/{st}/block</em>. Block url template</li><li> <strong>cbsa</string>, <em>censusgeo://2020/5/US/cbsa</em>. Metro areas</li><li> <strong>states</string>, <em>censusgeo://2020/5/US/state</em>. US States</li><li> <strong>us_geohashes</string>, <em>metapack+http://library.metatab.org/civicknowledge.com-geohash-us.csv#us_geohashes</em>. All 4 digit geohases in the continential US</li><li> <strong>utm_grid</string>, <em>metapack+http://library.metatab.org/civicknowledge.com-mgrs.csv#utm_grid</em>. </li><li> <strong><a href=\"https://www.census.gov/eos/www/naics/2012NAICS/2012_NAICS_Index_File.xls\">naics_index_2012</a></strong>. NAICS index file, 2012</li><li> <strong><a href=\"https://www.census.gov/eos/www/naics/2012NAICS/2-digit_2012_Codes.xls\">naics_index_2012_26</a></strong>. NAICS index file, 2012, 2 to 6 digit codes</li><li> <strong><a href=\"https://www.census.gov/naics/concordances/1997_NAICS_to_1987_SIC.xls\">naics_sic</a></strong>. NAICS to SIC crosswalk, maybe?</li><ul>"
      ],
      "text/plain": [
       "# US Businesses\n",
       "`businesslistdatabase.com-us_business-1.1.1` Last Update: 2021-04-09T23:19:03\n",
       "\n",
       "_US Business list, reduced to point position and category_\n",
       "\n",
       "\n",
       "\n",
       "This package processes a list of US businesses obtained from a\n",
       "[private source](https://www.businesslistdatabase.com/). The\n",
       "source data is low quality, so there is a lot of processing\n",
       "to be done. Most importantly, many records have a conflict between \n",
       "the SIC and NAICS codes; these records are removed. \n",
       "\n",
       "## Building\n",
       "\n",
       "The package can take muh longer to build than the timeout for \n",
       "running a Jupyter notebook, so the Jupyter notebook caches\n",
       "intermediate stages of the process. Run the upyter notebook directly\n",
       "first, then build the package.\n",
       "## Documentation Links\n",
       "\n",
       "* [Documentation Page](http://s3.amazonaws.com/radius.civicknowledge.com/businesslistdatabase.com-us_business-1.1.1/index.html) \n",
       "\n",
       " \n",
       "\n",
       "## Contacts\n",
       "\n",
       "* **Wrangler** [Eric Busboom](mailto:eric@civicknowledge.com), [Civic Knowledge](http://civicknowledge.com)\n",
       "\n",
       "## Resources\n",
       "\n",
       "* ** [businesses_cat](http://s3.amazonaws.com/radius.civicknowledge.com/businesslistdatabase.com-us_business-1.1.1/data/businesses_cat.csv)**. Businesses categorized to shop, auto, food, ent\n",
       "\n",
       "## References\n",
       "<ul><li> <strong>us_business</string>, <em>data/us_businesses.zip</em>. List of US Businesses</li><li> <strong>block_templ</string>, <em>censusgeo://2020/5/{st}/block</em>. Block url template</li><li> <strong>cbsa</string>, <em>censusgeo://2020/5/US/cbsa</em>. Metro areas</li><li> <strong>states</string>, <em>censusgeo://2020/5/US/state</em>. US States</li><li> <strong>us_geohashes</string>, <em>metapack+http://library.metatab.org/civicknowledge.com-geohash-us.csv#us_geohashes</em>. All 4 digit geohases in the continential US</li><li> <strong>utm_grid</string>, <em>metapack+http://library.metatab.org/civicknowledge.com-mgrs.csv#utm_grid</em>. </li><li> <strong><a href=\"https://www.census.gov/eos/www/naics/2012NAICS/2012_NAICS_Index_File.xls\">naics_index_2012</a></strong>. NAICS index file, 2012</li><li> <strong><a href=\"https://www.census.gov/eos/www/naics/2012NAICS/2-digit_2012_Codes.xls\">naics_index_2012_26</a></strong>. NAICS index file, 2012, 2 to 6 digit codes</li><li> <strong><a href=\"https://www.census.gov/naics/concordances/1997_NAICS_to_1987_SIC.xls\">naics_sic</a></strong>. NAICS to SIC crosswalk, maybe?</li><ul>\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpkg = mp.open_package('http://radius.civicknowledge.com.s3.amazonaws.com/businesslistdatabase.com-us_business.csv')\n",
    "bpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbsa = bpkg.reference('cbsa').geoframe()\n",
    "bc= bpkg.resource('businesses_cat').geoframe()\n",
    "t = gpd.sjoin(bc, cbsa.to_crs(4326))\n",
    "df = t[~t.geoid.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126724\n",
      "1009478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only need a subset of columns. \n",
    "t = df.reset_index()[['index', 'geoid', 'geometry']].copy().rename(columns={'index':'idx'})\n",
    "\n",
    "# Use geohashes to ensure only one point within each approx 150mx150m region\n",
    "import libgeohash as gh \n",
    "t['geohash'] = t.geometry.apply(lambda v: gh.encode(v.y, v.x, precision = 7) )\n",
    "\n",
    "print(len(t))\n",
    "t = t.drop_duplicates(subset=['geohash'])\n",
    "print(len(t))\n",
    "\n",
    "# Sample 100 records from every CBSA to ensure that in the final set, \n",
    "# each CBSA has at least 100. We'll remove duplicates later. \n",
    "def sample(g):\n",
    "    try:\n",
    "        return g.sample(100)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "df100 = t.groupby('geoid').apply(sample).reset_index(drop=True)\n",
    "\n",
    "# Sample the ballance of the 500k\n",
    "df400 = t[~t.idx.isin(df100.idx)].sample(500_000-len(df100))\n",
    "\n",
    "# combine the sets together. \n",
    "df500 = pd.concat([df400, df100]).sort_values('geoid').drop_duplicates(subset=['geohash'])\n",
    "\n",
    "\n",
    "len(df500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df500.to_csv('../data/business_points.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
